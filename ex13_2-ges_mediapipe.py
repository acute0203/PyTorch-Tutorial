import cv2
import mediapipe as mp
import math

# åˆå§‹åŒ– mediapipe
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# è¨ˆç®—å…©é»è·é›¢
def distance(a, b):
    return math.sqrt((a.x - b.x) ** 2 + (a.y - b.y) ** 2)

# åˆ¤æ–·å“ªäº›æ‰‹æŒ‡æ˜¯ä¼¸ç›´çš„ï¼ˆä¾æ“š landmark y å€¼ï¼‰
def get_finger_status(hand_landmarks):
    finger_status = []

    # æ‰‹æŒæ–¹å‘ï¼ˆåˆ¤æ–·æ˜¯å·¦æ‰‹é‚„æ˜¯å³æ‰‹ï¼‰
    wrist = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST]
    index_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]
    if wrist.x < index_mcp.x:
        is_right_hand = True
    else:
        is_right_hand = False

    # å¤§æ‹‡æŒ‡ (å·¦å³æ–¹å‘)
    thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]
    thumb_ip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP]
    if is_right_hand:
        finger_status.append(thumb_tip.x < thumb_ip.x)  # å³æ‰‹å¤§æ‹‡æŒ‡å‘å·¦å¼µé–‹
    else:
        finger_status.append(thumb_tip.x > thumb_ip.x)  # å·¦æ‰‹å¤§æ‹‡æŒ‡å‘å³å¼µé–‹

    # å…¶ä»–æ‰‹æŒ‡ (ç”±ä¸‹å¾€ä¸Šå¼µé–‹)
    tips = [mp_hands.HandLandmark.INDEX_FINGER_TIP,
            mp_hands.HandLandmark.MIDDLE_FINGER_TIP,
            mp_hands.HandLandmark.RING_FINGER_TIP,
            mp_hands.HandLandmark.PINKY_TIP]
    pips = [mp_hands.HandLandmark.INDEX_FINGER_PIP,
            mp_hands.HandLandmark.MIDDLE_FINGER_PIP,
            mp_hands.HandLandmark.RING_FINGER_PIP,
            mp_hands.HandLandmark.PINKY_PIP]

    for tip, pip in zip(tips, pips):
        finger_status.append(hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y)

    return finger_status  # [thumb, index, middle, ring, pinky]

# åˆ¤æ–·æ‰‹å‹¢
def detect_gesture(finger_status, landmarks):
    # ğŸ‘ æ¯”è®šï¼šåªæœ‰å¤§æ‹‡æŒ‡ä¼¸ç›´
    if finger_status == [True, False, False, False, False]:
        return "ğŸ‘ Thumbs Up"

    # ğŸ’— mini æ„›å¿ƒï¼šå¤§æ‹‡æŒ‡èˆ‡é£ŸæŒ‡æŒ‡å°–é è¿‘ï¼Œå…¶é¤˜å½æ›²
    d = distance(landmarks[mp_hands.HandLandmark.THUMB_TIP],
                 landmarks[mp_hands.HandLandmark.INDEX_FINGER_TIP])
    if d < 0.03 and finger_status[2:] == [False, False, False]:
        return "ğŸ’— Mini Heart"

    # æ•¸å­— 1~5ï¼šä¾æ“šå¼µé–‹æ‰‹æŒ‡çš„æ•¸é‡
    count = sum(finger_status)
    if 1 <= count <= 5:
        return f"ğŸ–ï¸ Number {count}"

    return None

# å•Ÿå‹•æ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

with mp_hands.Hands(
        max_num_hands=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as hands:

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # OpenCV å½±åƒå‰è™•ç†
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = hands.process(image)

        # OpenCV ç¹ªåœ–å¾Œè™•ç†
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # ç¹ªè£½é—œéµé»
                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)

                # æ‰‹å‹¢åˆ¤æ–·
                finger_status = get_finger_status(hand_landmarks)
                gesture = detect_gesture(finger_status, hand_landmarks.landmark)

                if gesture:
                    print(f"åµæ¸¬åˆ°æ‰‹å‹¢ï¼š{gesture}")
                    # å¯è¦–åŒ–æ¨™ç¤º
                    cv2.putText(image, gesture, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)

        cv2.imshow("Hand Gesture Recognition", image)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyAllWindows()
